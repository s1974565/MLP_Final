{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4897dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab09cb7",
   "metadata": {},
   "source": [
    "When no model is supplied, the pipeline automatically uses the default model associated with each task. You can find all available model choices in the following website: https://huggingface.co/models There are even some models for foreign languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6f3240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier_s = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751f67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_s = [\n",
    "    \"This is a testing sentence\",\n",
    "    \"This is another testing sentence, which is literally testing the pipeline function\",\n",
    "    \"I am not quite sure how to use this transformer libary, but I do like its high level functionalities\",\n",
    "    \"Hello my friend\",\n",
    "    \"Hello, Bart?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b339099d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.913568913936615},\n",
       " {'label': 'NEGATIVE', 'score': 0.9940857887268066},\n",
       " {'label': 'POSITIVE', 'score': 0.9987115859985352},\n",
       " {'label': 'POSITIVE', 'score': 0.9990572333335876},\n",
       " {'label': 'POSITIVE', 'score': 0.9946510195732117}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_s(sentences_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4628ffda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier_z = pipeline(\"zero-shot-classification\")\n",
    "sentences_z = [\n",
    "    \"This is a course about the Transformers library\",\n",
    "    \"I have used my keyboard for more than 10 years\",\n",
    "    \"I like to study Artificial Intelligence\"\n",
    "]\n",
    "labels_z = [\"Education\", \"Politics\", \"Business\", \"University\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be09db70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This is a course about the Transformers library',\n",
       "  'labels': ['University', 'Education', 'Business', 'Politics'],\n",
       "  'scores': [0.32160961627960205,\n",
       "   0.3018229603767395,\n",
       "   0.262361079454422,\n",
       "   0.11420632153749466]},\n",
       " {'sequence': 'I have used my keyboard for more than 10 years',\n",
       "  'labels': ['Business', 'University', 'Education', 'Politics'],\n",
       "  'scores': [0.3691573143005371,\n",
       "   0.26054561138153076,\n",
       "   0.2151063233613968,\n",
       "   0.15519072115421295]},\n",
       " {'sequence': 'I like to study Artificial Intelligence',\n",
       "  'labels': ['University', 'Business', 'Education', 'Politics'],\n",
       "  'scores': [0.6254051327705383,\n",
       "   0.16458508372306824,\n",
       "   0.12717516720294952,\n",
       "   0.08283459395170212]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_z(sentences_z, labels_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8841aa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "generator_g = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad31816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "C:\\Users\\Jinyoung\\anaconda3\\envs\\mlp\\lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to create and manage accounts and how to change and manage email from a mobile device.\\n\\nThe Course Overview in this course is aimed at students looking for a start in using Google Gmail with Google account management'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_g(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e71d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to develop and utilize more of your personal data. This course will be the first step in the transformation of your lives — in your own data, in your personal conversations…\\n\\n*This course is for'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_g(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb739c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to construct a simple Python command-line program for you to use with your Python-enabled devices.\\n\\nTo make the command line program easy to create, use python and make.\\n\\nIt will compile the current directory, then execute the python-config command.\\n\\nThen it will run all the commands you may already have. It is recommended to ensure that the directories in your current directory are identical.\\n\\nTo make sure that your Python'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_g(\"In this course, we will teach you how to\", max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c9d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the lighter version of GPT2 created by the Hugging Face team\n",
    "generator_gl = pipeline(\"text-generation\", model=\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31792f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In the year 2023, it is expected to add at least five to five more years, with the average annual value of about $10,000 per year.'},\n",
       " {'generated_text': 'In the year 2023, it is expected to see more women entering the workforce. If so, the United States currently stands at 25,000 women, the U.S. would be the 12th most active state in terms of workforce participation since 1972.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_gl(\"In the year 2023, it is expected to\", max_length=100, num_return_sequences=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c769d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1961977779865265,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052717983722687,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It appears that there is no randomness in this model.\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ca188ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\Jinyoung\\anaconda3\\envs\\mlp\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9965486,\n",
       "  'word': 'Jinyoung',\n",
       "  'start': 11,\n",
       "  'end': 19},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.73366773,\n",
       "  'word': '##ial Intelligence',\n",
       "  'start': 39,\n",
       "  'end': 55},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9847757,\n",
       "  'word': 'University of Edinburgh',\n",
       "  'start': 63,\n",
       "  'end': 86}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "# grouped_entities=True makes the model to group words in the same entity.\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Jinyoung and I study Artificial Intelligence in the University of Edinburgh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f5d33da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.98528486,\n",
       "  'word': 'Jinyoung',\n",
       "  'start': 0,\n",
       "  'end': 8},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99805605,\n",
       "  'word': 'UOE',\n",
       "  'start': 30,\n",
       "  'end': 33},\n",
       " {'entity_group': 'MISC',\n",
       "  'score': 0.93869734,\n",
       "  'word': 'AI',\n",
       "  'start': 47,\n",
       "  'end': 49},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9982577,\n",
       "  'word': 'Edinburgh',\n",
       "  'start': 67,\n",
       "  'end': 76}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"Jinyoung, who is a student of UOE, is studying AI. He is living in Edinburgh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3168b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "question = \"Where do I study?\"\n",
    "question_wrong = \"Wher I stdy do?\"\n",
    "\n",
    "context = \"My name is Jinyoung, and I study AI at the University of Edinburgh\"\n",
    "context_wrong = \"my nam is Jinyoung, and study I ai at univ of edinburgh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94484fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.5356670618057251,\n",
       " 'start': 43,\n",
       " 'end': 66,\n",
       " 'answer': 'University of Edinburgh'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a2abf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.25569677352905273,\n",
       " 'start': 24,\n",
       " 'end': 55,\n",
       " 'answer': 'study I ai at univ of edinburgh'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(question=question_wrong, context=context_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db4eadde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "summariser = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6649af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = \"\"\"The UK's largest supermarket, Tesco, and discounter Aldi have said they are putting limits of three per customer on sales of tomatoes, peppers, and cucumbers. \n",
    "Asda has capped sales of lettuce, salad bags, broccoli, cauliflowers and raspberry punnets to three per customer, along with tomatoes, peppers and cucumbers. \n",
    "And Morrisons has set limits of two on cucumbers, tomatoes, lettuce and peppers. \n",
    "Tomatoes and peppers seem to be the worst affected at both retailers but its unclear whether this is because they are popular.\n",
    "Other major UK supermarkets have also been hit by the shortages but have not yet introduced limits for customers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d42b89c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 141. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=70)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Tesco and Aldi have said they are putting limits of three per customer on sales of tomatoes, peppers, and cucumbers . Asda has capped sales of lettuce, salad bags, broccoli, cauliflowers and raspberry punnets . Morrisons has set limits of two on cucumbers, tomatoes, lettuce and peppers .'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summariser(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a87a871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578aba53ff86411ab0234ce65bd028a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef0c193f99545cc9c2e7948f7fee77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1fb8efaab85454582eb4718bf665db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinyoung\\anaconda3\\envs\\mlp\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "translator_fe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab4f0ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator_fe(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e73a1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
