{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7fa15e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# Sentence similarity model\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Baseline model 1\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f883968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU acceleration is available\n",
    "if torch.cuda.is_available():\n",
    "    device_num = torch.cuda.current_device()\n",
    "else:\n",
    "    # CPU\n",
    "    device_num = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c700cacb",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a61540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonl_list_to_dataframe(file_list, columns=None):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, orient='records', compression='gzip', lines=True)[columns] for f in file_list], \n",
    "                     sort=False)\n",
    "def get_dfs(path):\n",
    "    \"\"\"Grabs the different data splits and converts them into dataframes\"\"\"\n",
    "    dfs = []\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "        files = sorted(glob.glob(path+\"/\"+split+\"**/*.gz\"))\n",
    "        df = jsonl_list_to_dataframe(files, [\"func_name\", \"code\", \"code_tokens\", \"repo\"])\n",
    "        dfs.append(df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ea4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For saving the original files into pickle files.\n",
    "# df_train, df_valid, df_test = get_dfs(\"data/codenet/python/final/jsonl\")\n",
    "\n",
    "# df_train.to_pickle(\"train.pickle\")\n",
    "# df_valid.to_pickle(\"valid.pickle\")\n",
    "# df_test.to_pickle(\"test.pickle\")\n",
    "\n",
    "df_train = pd.read_pickle(\"train.pickle\").reset_index(drop=True)\n",
    "df_valid = pd.read_pickle(\"valid.pickle\").reset_index(drop=True)\n",
    "df_test = pd.read_pickle(\"test.pickle\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b010b5",
   "metadata": {},
   "source": [
    "### Helper methods for baseline models testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4644023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_print(input_sequence, unmasker, true_labels=None, top_k=2, mask_token=\"<mask>\"):\n",
    "    mask_num = input_sequence.count(mask_token)\n",
    "    output = unmasker(input_sequence, top_k=top_k)\n",
    "    if mask_num == 1:\n",
    "        print(\"-\" * 50)\n",
    "        if true_labels:\n",
    "            print(f\"True label: {true_labels[0]}\")\n",
    "            print(\"\")\n",
    "        for candidate in output:\n",
    "            print(f\"Predicted_word: {candidate['token_str']}\")\n",
    "            print(f\"Probability: {round(candidate['score'], 3)}\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"\")\n",
    "        \n",
    "    else:\n",
    "        for index, word_prediction in enumerate(output):\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"Mask number: {index}\")\n",
    "            if true_labels:\n",
    "                print(f\"True label: {true_labels[index]}\")\n",
    "                print(\"\")\n",
    "            for candidate in word_prediction:\n",
    "                print(f\"Predicted_word: {candidate['token_str']}\")\n",
    "                print(f\"Probability: {round(candidate['score'], 3)}\")\n",
    "            print(\"-\" * 50)\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605b5645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def learn(env,\\n          network,\\n          seed=None,\\n          callback=None,\\n          load_path=None,\\n          **network_kwargs\\n            )',\n",
       " '# Create all the functions necessary to train the model\\n',\n",
       " 'sess = get_session()\\n',\n",
       " 'q_func = build_q_func(network, **network_kwargs)\\n',\n",
       " '# capture the shape outside the closure so that the env object is not serialized\\n',\n",
       " '# by cloudpickle when serializing make_obs_ph\\n',\n",
       " 'observation_space = env.observation_space\\n',\n",
       " 'def make_obs_ph(name)',\n",
       " 'return ObservationInput(observation_space, name=name)\\n',\n",
       " 'act, train, update_target, debug = deepq.build_train(\\n',\n",
       " 'make_obs_ph=make_obs_ph,\\n',\n",
       " 'q_func=q_func,\\n',\n",
       " 'num_actions=env.action_space.n,\\n',\n",
       " 'optimizer=tf.train.AdamOptimizer(learning_rate=lr),\\n',\n",
       " 'gamma=gamma,\\n',\n",
       " 'grad_norm_clipping=10,\\n',\n",
       " 'param_noise=param_noise\\n',\n",
       " 'act_params = {\\n',\n",
       " 'act = ActWrapper(act, act_params)\\n',\n",
       " '# Create the replay buffer\\n',\n",
       " 'replay_buffer = PrioritizedReplayBuffer(buffer_size, alpha=prioritized_replay_alpha)\\n',\n",
       " 'prioritized_replay_beta_iters = total_timesteps\\n',\n",
       " 'beta_schedule = LinearSchedule(prioritized_replay_beta_iters,\\n',\n",
       " 'initial_p=prioritized_replay_beta0,\\n',\n",
       " 'final_p=1.0)\\n',\n",
       " 'replay_buffer = ReplayBuffer(buffer_size)\\n',\n",
       " 'beta_schedule = None\\n',\n",
       " '# Create the schedule for exploration starting from 1.\\n',\n",
       " 'exploration = LinearSchedule(schedule_timesteps=int(exploration_fraction * total_timesteps),\\n',\n",
       " 'initial_p=1.0,\\n',\n",
       " 'final_p=exploration_final_eps)\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable masker testing\n",
    "test = \"\"\"\n",
    "def learn(env,\n",
    "          network,\n",
    "          seed=None,\n",
    "          callback=None,\n",
    "          load_path=None,\n",
    "          **network_kwargs\n",
    "            ):\n",
    "    act: ActWrapper\n",
    "        Wrapper over act function. Adds ability to save it and load it.\n",
    "        See header of baselines/deepq/categorical.py for details on the act function.\n",
    "    # Create all the functions necessary to train the model\n",
    "\n",
    "    sess = get_session()\n",
    "    set_global_seeds(seed)\n",
    "\n",
    "    q_func = build_q_func(network, **network_kwargs)\n",
    "\n",
    "    # capture the shape outside the closure so that the env object is not serialized\n",
    "    # by cloudpickle when serializing make_obs_ph\n",
    "\n",
    "    observation_space = env.observation_space\n",
    "    def make_obs_ph(name):\n",
    "        return ObservationInput(observation_space, name=name)\n",
    "\n",
    "    act, train, update_target, debug = deepq.build_train(\n",
    "        make_obs_ph=make_obs_ph,\n",
    "        q_func=q_func,\n",
    "        num_actions=env.action_space.n,\n",
    "        optimizer=tf.train.AdamOptimizer(learning_rate=lr),\n",
    "        gamma=gamma,\n",
    "        grad_norm_clipping=10,\n",
    "        param_noise=param_noise\n",
    "    )\n",
    "\n",
    "    act_params = {\n",
    "        'make_obs_ph': make_obs_ph,\n",
    "        'q_func': q_func,\n",
    "        'num_actions': env.action_space.n,\n",
    "    }\n",
    "\n",
    "    act = ActWrapper(act, act_params)\n",
    "\n",
    "    # Create the replay buffer\n",
    "    if prioritized_replay:\n",
    "        replay_buffer = PrioritizedReplayBuffer(buffer_size, alpha=prioritized_replay_alpha)\n",
    "        if prioritized_replay_beta_iters is None:\n",
    "            prioritized_replay_beta_iters = total_timesteps\n",
    "        beta_schedule = LinearSchedule(prioritized_replay_beta_iters,\n",
    "                                       initial_p=prioritized_replay_beta0,\n",
    "                                       final_p=1.0)\n",
    "    else:\n",
    "        replay_buffer = ReplayBuffer(buffer_size)\n",
    "        beta_schedule = None\n",
    "    # Create the schedule for exploration starting from 1.\n",
    "    exploration = LinearSchedule(schedule_timesteps=int(exploration_fraction * total_timesteps),\n",
    "                                 initial_p=1.0,\n",
    "                                 final_p=exploration_final_eps)\n",
    "\"\"\"\n",
    "\n",
    "pattern = r\"(\\bdef\\s\\w*\\(.*?\\)):|(#\\s*.*?\\n)|(return\\s*.*?\\n)|(\\b[\\w,\\s]*=\\s*.*?\\n)\"\n",
    "matches = [str().join(x) for x in re.findall(pattern, test, flags=re.DOTALL)]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0784c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic assumption: The same line of code never occurs twice.\n",
    "def mask_variable_names(code, mask_prob):\n",
    "    \"\"\"\n",
    "    Mask the values of variables in a code with a certain probability.\n",
    "    \"\"\"\n",
    "    # Regular expression pattern to match variable assignments\n",
    "    # Function signature (to be filtered out later) | common variable definitions\n",
    "    pattern = r\"(\\bdef\\s\\w*\\(.*?\\)):|(#\\s*.*?\\n)|(return\\s*.*?\\n)|(\\b[\\w,\\s]*=\\s*.*?\\n)\"\n",
    "    matches = [str().join(x) for x in re.findall(pattern, code, flags=re.DOTALL)]\n",
    "    var_indices = list()\n",
    "    var_labels = list()\n",
    "    # characters that should not exist in the first sub part of a found match.\n",
    "    invalid_list = [\"(\", \")\", \"def\", \"#\", \"return\"]\n",
    "    \n",
    "    # If there is a variable found\n",
    "    if matches:\n",
    "        for match in matches:\n",
    "            # Split the match into sub-parts by the equal sign, and check if the first sub-part contain any parenthesis\n",
    "            # or \"def\" (implies function signature).\n",
    "            # If not, then the first sub-part is variable(s).\n",
    "            first_sub_part = match.split(\"=\")[0]\n",
    "            if not any([invalid_character in first_sub_part for invalid_character in invalid_list]):\n",
    "                variables = set(re.split(\",|=\", first_sub_part))\n",
    "                \n",
    "                # Masking variables based on the mask_prob\n",
    "                masked_match = str(match)\n",
    "                match_begin_index = code.find(masked_match)\n",
    "                for var in variables:\n",
    "                    # If beginning of the function call, then process no further.\n",
    "                    if \"(\" in var:\n",
    "                        break\n",
    "                    if np.random.uniform() < mask_prob:\n",
    "                        var_begin_index = masked_match.find(var.strip())\n",
    "                        var_index = (var_begin_index + match_begin_index, var_begin_index + match_begin_index + len(var.strip()))\n",
    "                        var_indices.append(var_index)\n",
    "                        var_labels.append(var.strip())\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        return var_indices, var_labels\n",
    "    \n",
    "    # If no variable is found\n",
    "    else:\n",
    "        return code, list()\n",
    "        \n",
    "def mask_variable_df(df, code_column_name=\"code\", mask_prob=0.5, return_df=True):\n",
    "    variable_indices_list = list()\n",
    "    variable_labels_list = list()\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        variable_indices, variable_labels = mask_variable_names(row[\"code\"], mask_prob)\n",
    "        variable_indices_list.append(variable_indices)\n",
    "        variable_labels_list.append(variable_labels)\n",
    "        \n",
    "    if return_df:\n",
    "        return pd.DataFrame({\"variable_indices\" : variable_indices_list, \"variable_labels\" : variable_labels_list})\n",
    "    else:\n",
    "        return variable_indices_list, variable_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "250b2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_se = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "def cosine_similarity(sentences, model=model_se):\n",
    "    embeddings = model.encode(sentences)\n",
    "    return np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fec8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_docstring(code):\n",
    "    pattern = r'(\"\"\".*?\"\"\")|(\\'\\'\\'.*?\\'\\'\\')'\n",
    "    return re.sub(pattern, '', code, flags=re.DOTALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e4a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_substring_indices(text, substring):\n",
    "    pattern = re.compile(f'{substring}')\n",
    "    indices = [(match.start(), match.end()-1) for match in pattern.finditer(text)]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9d2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_windows(row, window_size, mask_token):\n",
    "    windows = list()\n",
    "    \n",
    "    for variable_indices, variable_labels in zip(row[\"variable_indices\"], row[\"variable_labels\"]):\n",
    "        # Window indices\n",
    "        begin_index = variable_indices[0] - window_size if variable_indices[0] - window_size > 0 else 0\n",
    "        end_index = variable_indices[1] + window_size if variable_indices[1] + window_size < len(row[\"code\"]) else len(row[\"code\"])\n",
    "        \n",
    "        current_window = row[\"code\"][begin_index : variable_indices[0]] + mask_token + row[\"code\"][variable_indices[1] : end_index]\n",
    "        windows.append(current_window)\n",
    "        \n",
    "#         print(current_window)\n",
    "#         print(\"--------\")\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a4c9190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the prediction to the given masked code. If top_k is bigger than 1, then the top_k predictions\n",
    "# will be concatenated by the given top_k_connection. Each prediction(s) will be stripped to remove unnecessary whitespaces.\n",
    "def mask_prediction(row, top_k, unmasker, top_k_connection, mask_token, window_size):\n",
    "    mask_num = len(row[\"variable_indices\"])\n",
    "    predictions = list()\n",
    "    \n",
    "    if mask_num == 0:\n",
    "        return predictions\n",
    "    \n",
    "#     elif mask_num == 1:\n",
    "#         window = split_into_windows(masked_code, window_size, mask_token, true_labels)\n",
    "#         output = unmasker(window, top_k=top_k)\n",
    "#         candidate_concat = top_k_connection.join([candidate['token_str'].strip() for candidate in output])\n",
    "#         predictions.append(candidate_concat)\n",
    "#         return predictions\n",
    "    \n",
    "    else:\n",
    "        windows = split_into_windows(row, window_size, mask_token)\n",
    "        for window in windows:\n",
    "            output = unmasker(window, top_k=top_k)\n",
    "            candidate_concat = top_k_connection.join([candidate['token_str'].strip() for candidate in output])\n",
    "            predictions.append(candidate_concat)\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd68e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the given code dataframe, it automatically masks the codes and fill the masks by the supplied unmasker.\n",
    "# The predicted results are then compared with the true labels, with cosine similarity.\n",
    "# If top_k is set bigger than 1, then top_k number of predictions will be concatenated to form a single predictions\n",
    "# by the top_k_connection (default to the underscore).\n",
    "# For example, if the predictions are: \"A\", \"B\", and \"C\", then top_k = 2, the final prediction will be \"A_B\".\n",
    "\n",
    "# Currently runtime errors will be ignored. Runtime errors happen when the given code is longer than the maximum\n",
    "# size of the unmasker model (512 tokens)\n",
    "\n",
    "# Pre-trained transformers typically can take up to 512 tokens. Thus, if the given code is larger than this,\n",
    "# then a RuntimeError will be raised. To avoid this, the window_size variable is added. It regulates the amount of\n",
    "# context which will be give to the unmasker. If it is set to 100, total 200 characters will be given to the unmasker:\n",
    "# 100 characters before the mask token, and 100 characters after the mask token.\n",
    "# For example, 100 characters <mask> 100 characters\n",
    "def baseline_test(code_df, unmasker, mask_token=\"<mask>\", mask_prob=0.5, top_k=1, top_k_connection=\"_\", \n",
    "                  code_column_name=\"code\", window_size=100):\n",
    "    \n",
    "    masked_code_df = mask_variable_df(code_df, mask_prob=mask_prob, code_column_name=code_column_name)\n",
    "    merged_code_df = pd.concat([code_df, masked_code_df], axis=\"columns\")\n",
    "    \n",
    "    similarity_scores_list = list()\n",
    "    predictions_list = list()\n",
    "    true_labels_list = list()\n",
    "    \n",
    "    total_size = len(code_df)\n",
    "    for index, row in merged_code_df.iterrows():\n",
    "        if index % 1000 == 0:\n",
    "            print(f\"Progress: {round(index / total_size, 3) * 100}%\")\n",
    "        \n",
    "        true_labels = row[\"variable_labels\"]\n",
    "        true_labels_list.append(true_labels)\n",
    "        \n",
    "        # If the current code snippet is longer than the maximum input size of the given unmasker \n",
    "        # then the runtime error will be raised. Try to reduce window_size.\n",
    "        try:\n",
    "            predictions = mask_prediction(row, top_k, unmasker, top_k_connection, mask_token, window_size)\n",
    "            predictions_list.append(predictions)\n",
    "        except RuntimeError:\n",
    "            raise RuntimeError(\"The given input size is bigger than the maximum model input. Reduce the window size.\")\n",
    "        \n",
    "        similarity_scores = list()\n",
    "        for prediction, true_label in zip(predictions, true_labels):\n",
    "            similarity_scores.append(cosine_similarity([prediction, true_label]))\n",
    "        similarity_scores_list.append(similarity_scores)\n",
    "        \n",
    "    return predictions_list, true_labels_list, similarity_scores_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc2c9f",
   "metadata": {},
   "source": [
    "### Baseline score 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480788bc",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/microsoft/codebert-base-mlm <br>\n",
    "As stated in https://github.com/microsoft/CodeBERT, the basic CobeBERT is not suitable for filling-mask task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70fd1e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b1 = RobertaForMaskedLM.from_pretrained('microsoft/codebert-base-mlm')\n",
    "tokenizer_b1 = RobertaTokenizer.from_pretrained('microsoft/codebert-base-mlm')\n",
    "fill_mask_b1 = pipeline('fill-mask', model=model_b1, tokenizer=tokenizer_b1, device=device_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9aaf530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Predicted_word:  and\n",
      "Probability: 0.724\n",
      "Predicted_word:  &\n",
      "Probability: 0.106\n",
      "Predicted_word: and\n",
      "Probability: 0.022\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code_example = \"if (x is not None) <mask> (x>1)\"\n",
    "output_print(code_example, fill_mask_b1, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a228f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40455922"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "model_ss = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "cosine_similarity(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae1abd12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinyoung\\anaconda3\\envs\\mlp\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 4.3%\n",
      "Progress: 8.7%\n",
      "Progress: 13.0%\n",
      "Progress: 17.299999999999997%\n",
      "Progress: 21.6%\n",
      "Progress: 26.0%\n",
      "Progress: 30.3%\n",
      "Progress: 34.599999999999994%\n",
      "Progress: 38.9%\n",
      "Progress: 43.3%\n",
      "Progress: 47.599999999999994%\n",
      "Progress: 51.9%\n",
      "Progress: 56.3%\n",
      "Progress: 60.6%\n",
      "Progress: 64.9%\n",
      "Progress: 69.19999999999999%\n",
      "Progress: 73.6%\n",
      "Progress: 77.9%\n",
      "Progress: 82.19999999999999%\n",
      "Progress: 86.6%\n",
      "Progress: 90.9%\n",
      "Progress: 95.19999999999999%\n",
      "Progress: 99.5%\n",
      "Finished\n",
      "Progress: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinyoung\\anaconda3\\envs\\mlp\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 4.3%\n",
      "Progress: 8.7%\n",
      "Progress: 13.0%\n",
      "Progress: 17.299999999999997%\n",
      "Progress: 21.6%\n",
      "Progress: 26.0%\n",
      "Progress: 30.3%\n",
      "Progress: 34.599999999999994%\n",
      "Progress: 38.9%\n",
      "Progress: 43.3%\n",
      "Progress: 47.599999999999994%\n",
      "Progress: 51.9%\n",
      "Progress: 56.3%\n",
      "Progress: 60.6%\n",
      "Progress: 64.9%\n",
      "Progress: 69.19999999999999%\n",
      "Progress: 73.6%\n",
      "Progress: 77.9%\n",
      "Progress: 82.19999999999999%\n",
      "Progress: 86.6%\n",
      "Progress: 90.9%\n",
      "Progress: 95.19999999999999%\n",
      "Progress: 99.5%\n",
      "Finished\n",
      "Progress: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinyoung\\anaconda3\\envs\\mlp\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 4.3%\n",
      "Progress: 8.7%\n",
      "Progress: 13.0%\n",
      "Progress: 17.299999999999997%\n",
      "Progress: 21.6%\n",
      "Progress: 26.0%\n",
      "Progress: 30.3%\n",
      "Progress: 34.599999999999994%\n",
      "Progress: 38.9%\n",
      "Progress: 43.3%\n",
      "Progress: 47.599999999999994%\n",
      "Progress: 51.9%\n",
      "Progress: 56.3%\n",
      "Progress: 60.6%\n",
      "Progress: 64.9%\n",
      "Progress: 69.19999999999999%\n",
      "Progress: 73.6%\n",
      "Progress: 77.9%\n",
      "Progress: 82.19999999999999%\n",
      "Progress: 86.6%\n",
      "Progress: 90.9%\n",
      "Progress: 95.19999999999999%\n",
      "Progress: 99.5%\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# It takes a lot of time, even though GPU acceleration is applied. It is because of many variables in each code snippet\n",
    "# and using the dataframe, not the huggingface api dataset. It should be refactored soon.\n",
    "# I do recommend to load the pickle files I saved below, instead of running this again.\n",
    "\n",
    "# You can just implement another metric and use it instead (implementation of perplexity should be straightforward).\n",
    "\n",
    "# top_k = 1\n",
    "b1_result_k1 = baseline_test(df_valid, fill_mask_b1, top_k=1)\n",
    "print(\"Finished\")\n",
    "\n",
    "# top_k = 2\n",
    "b1_result_k2 = baseline_test(df_valid, fill_mask_b1, top_k=2, mask_prob=1)\n",
    "print(\"Finished\")\n",
    "\n",
    "# top_k = 3\n",
    "b1_result_k3 = baseline_test(df_valid, fill_mask_b1, top_k=3)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8120ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out to prevent accidently overwriting these files.\n",
    "\n",
    "with open(\"b1_result_k1.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(b1_result_k1, fw)\n",
    "\n",
    "with open(\"b1_result_k2.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(b1_result_k2, fw)\n",
    "\n",
    "with open(\"b1_result_k3.pickle\", \"wb\") as fw:\n",
    "    pickle.dump(b1_result_k3, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b806487",
   "metadata": {},
   "source": [
    "### For debug (Printing out all windows)\n",
    "\n",
    "To use, uncomment the following two lines in the function \"split_into_windows\" <br>\n",
    "print(current_window) <br>\n",
    "print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_test(df_valid.head(1), fill_mask_b1, top_k=1, mask_prob=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_valid.loc[0, 'code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a804e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62429af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final testing (in progress)\n",
    "\n",
    "# print(\"Total mean value of all cosine similarities\")\n",
    "# for index, result in enumerate([b1_result_k1, b1_result_k2, b1_result_k3]):\n",
    "#     similarity_scores_list = result[2]\n",
    "#     total_values = 0\n",
    "#     total_mask_num = 0\n",
    "#     for similarity_scores in similarity_scores_list:\n",
    "#         if similarity_scores:\n",
    "#             total_values += np.sum(similarity_scores)\n",
    "#             total_mask_num += len(similarity_scores)\n",
    "    \n",
    "#     total_average = total_values / total_mask_num\n",
    "#     print(f\"Top_k={index+1}\\n Total mask number: {total_mask_num}, Total average cosine similarity: {round(total_average, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461527e3",
   "metadata": {},
   "source": [
    "### Baseline score 2: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
