{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import torch\n",
    "\n",
    "# Helpers\n",
    "from testing import *\n",
    "# Huggingface dataset\n",
    "from datasets import Dataset\n",
    "# Baseline model 1\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_valid, df_test = loading_pickles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>func_name</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learn</td>\n",
       "      <td>def learn(env,\\n          network,\\n          ...</td>\n",
       "      <td>[def, learn, (, env, ,, network, ,, seed, =, N...</td>\n",
       "      <td>openai/baselines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ActWrapper.save_act</td>\n",
       "      <td>def save_act(self, path=None):\\n        \"\"\"Sav...</td>\n",
       "      <td>[def, save_act, (, self, ,, path, =, None, ), ...</td>\n",
       "      <td>openai/baselines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nature_cnn</td>\n",
       "      <td>def nature_cnn(unscaled_images, **conv_kwargs)...</td>\n",
       "      <td>[def, nature_cnn, (, unscaled_images, ,, *, *,...</td>\n",
       "      <td>openai/baselines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>def mlp(num_layers=2, num_hidden=64, activatio...</td>\n",
       "      <td>[def, mlp, (, num_layers, =, 2, ,, num_hidden,...</td>\n",
       "      <td>openai/baselines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lstm</td>\n",
       "      <td>def lstm(nlstm=128, layer_norm=False):\\n    \"\"...</td>\n",
       "      <td>[def, lstm, (, nlstm, =, 128, ,, layer_norm, =...</td>\n",
       "      <td>openai/baselines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23102</th>\n",
       "      <td>Clifier.show_version</td>\n",
       "      <td>def show_version(self):\\n        \"\"\" custom co...</td>\n",
       "      <td>[def, show_version, (, self, ), :, class, Show...</td>\n",
       "      <td>xnuinside/clifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23103</th>\n",
       "      <td>Clifier.check_path_action</td>\n",
       "      <td>def check_path_action(self):\\n        \"\"\" cust...</td>\n",
       "      <td>[def, check_path_action, (, self, ), :, class,...</td>\n",
       "      <td>xnuinside/clifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23104</th>\n",
       "      <td>new_user</td>\n",
       "      <td>def new_user(yaml_path):\\n    '''\\n    Return ...</td>\n",
       "      <td>[def, new_user, (, yaml_path, ), :, print, 'Re...</td>\n",
       "      <td>tklovett/PyShirtsIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23105</th>\n",
       "      <td>_AddPropertiesForExtensions</td>\n",
       "      <td>def _AddPropertiesForExtensions(descriptor, cl...</td>\n",
       "      <td>[def, _AddPropertiesForExtensions, (, descript...</td>\n",
       "      <td>ibelie/typy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23106</th>\n",
       "      <td>_InternalUnpackAny</td>\n",
       "      <td>def _InternalUnpackAny(msg):\\n  \"\"\"Unpacks Any...</td>\n",
       "      <td>[def, _InternalUnpackAny, (, msg, ), :, type_u...</td>\n",
       "      <td>ibelie/typy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23107 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         func_name  \\\n",
       "0                            learn   \n",
       "1              ActWrapper.save_act   \n",
       "2                       nature_cnn   \n",
       "3                              mlp   \n",
       "4                             lstm   \n",
       "...                            ...   \n",
       "23102         Clifier.show_version   \n",
       "23103    Clifier.check_path_action   \n",
       "23104                     new_user   \n",
       "23105  _AddPropertiesForExtensions   \n",
       "23106           _InternalUnpackAny   \n",
       "\n",
       "                                                    code  \\\n",
       "0      def learn(env,\\n          network,\\n          ...   \n",
       "1      def save_act(self, path=None):\\n        \"\"\"Sav...   \n",
       "2      def nature_cnn(unscaled_images, **conv_kwargs)...   \n",
       "3      def mlp(num_layers=2, num_hidden=64, activatio...   \n",
       "4      def lstm(nlstm=128, layer_norm=False):\\n    \"\"...   \n",
       "...                                                  ...   \n",
       "23102  def show_version(self):\\n        \"\"\" custom co...   \n",
       "23103  def check_path_action(self):\\n        \"\"\" cust...   \n",
       "23104  def new_user(yaml_path):\\n    '''\\n    Return ...   \n",
       "23105  def _AddPropertiesForExtensions(descriptor, cl...   \n",
       "23106  def _InternalUnpackAny(msg):\\n  \"\"\"Unpacks Any...   \n",
       "\n",
       "                                             code_tokens                 repo  \n",
       "0      [def, learn, (, env, ,, network, ,, seed, =, N...     openai/baselines  \n",
       "1      [def, save_act, (, self, ,, path, =, None, ), ...     openai/baselines  \n",
       "2      [def, nature_cnn, (, unscaled_images, ,, *, *,...     openai/baselines  \n",
       "3      [def, mlp, (, num_layers, =, 2, ,, num_hidden,...     openai/baselines  \n",
       "4      [def, lstm, (, nlstm, =, 128, ,, layer_norm, =...     openai/baselines  \n",
       "...                                                  ...                  ...  \n",
       "23102  [def, show_version, (, self, ), :, class, Show...    xnuinside/clifier  \n",
       "23103  [def, check_path_action, (, self, ), :, class,...    xnuinside/clifier  \n",
       "23104  [def, new_user, (, yaml_path, ), :, print, 'Re...  tklovett/PyShirtsIO  \n",
       "23105  [def, _AddPropertiesForExtensions, (, descript...          ibelie/typy  \n",
       "23106  [def, _InternalUnpackAny, (, msg, ), :, type_u...          ibelie/typy  \n",
       "\n",
       "[23107 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "func_name                                                  learn\n",
       "code           def learn(env,\\n          network,\\n          ...\n",
       "code_tokens    [def, learn, (, env, ,, network, ,, seed, =, N...\n",
       "repo                                            openai/baselines\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def baseline_test(code_df, unmasker, mask_token=\"<mask>\", mask_prob=0.5, top_k=1, top_k_connection=\"_\",\n",
    "                  code_column_name=\"code\", window_size=100):\n",
    "    \"\"\"\n",
    "    For the given code dataframe, it automatically masks the codes and fill the masks by the supplied unmasker.\n",
    "    The predicted results are then compared with the true labels, with cosine similarity.\n",
    "    If top_k is set bigger than 1, then top_k number of predictions will be concatenated to form a single predictions\n",
    "    by the top_k_connection (default to the underscore).\n",
    "    For example, if the predictions are: \"A\", \"B\", and \"C\", then top_k = 2, the final prediction will be \"A_B\".\n",
    "\n",
    "    Pre-trained transformers typically can take up to 512 tokens. Thus, if the given code is larger than this,\n",
    "    then a RuntimeError will be raised. To avoid this, the window_size variable is added. It regulates the amount of\n",
    "    context which will be give to the unmasker. If it is set to 100, total 200 characters will be given to the unmasker:\n",
    "    100 characters before the mask token, and 100 characters after the mask token.\n",
    "    For example, 100 characters <mask> 100 characters\n",
    "    \"\"\"\n",
    "    masked_code_df = mask_variable_df(code_df, mask_prob=mask_prob, code_column_name=code_column_name)\n",
    "    merged_code_df = pd.concat([code_df, masked_code_df], axis=\"columns\")\n",
    "\n",
    "    similarity_scores_list = list()\n",
    "    predictions_list = list()\n",
    "    true_labels_list = list()\n",
    "\n",
    "    total_size = len(code_df)\n",
    "    for index, row in merged_code_df.iterrows():\n",
    "        if index % 1000 == 0:\n",
    "            print(f\"Progress: {round(index / total_size, 3) * 100}%\")\n",
    "\n",
    "        true_labels = row[\"variable_labels\"]\n",
    "        true_labels_list.append(true_labels)\n",
    "\n",
    "        # If the current code snippet is longer than the maximum input size of the given unmasker\n",
    "        # then the runtime error will be raised. Try to reduce window_size.\n",
    "        try:\n",
    "            predictions = mask_prediction(row, top_k, unmasker, top_k_connection, mask_token, window_size)\n",
    "            predictions_list.append(predictions)\n",
    "        except RuntimeError:\n",
    "            raise RuntimeError(\"The given input size is bigger than the maximum model input. Reduce the window size.\")\n",
    "\n",
    "        similarity_scores = list()\n",
    "        for prediction, true_label in zip(predictions, true_labels):\n",
    "            similarity_scores.append(cosine_similarity([prediction, true_label]))\n",
    "        similarity_scores_list.append(similarity_scores)\n",
    "\n",
    "    return predictions_list, true_labels_list, similarity_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_valid_masked = mask_variable_df(df_valid[:10])\n",
    "df_valid_merged = pd.concat([df_valid[:10], df_valid_masked], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_into_windows(row, window_size, mask_token, testing=False):\n",
    "    windows = list()\n",
    "\n",
    "    for variable_indices, variable_labels in zip(row[\"variable_indices\"], row[\"variable_labels\"]):\n",
    "        # Window indices\n",
    "        begin_index = variable_indices[0] - window_size if variable_indices[0] - window_size > 0 else 0\n",
    "        end_index = variable_indices[1] + window_size if variable_indices[1] + window_size < len(row[\"code\"]) else len(\n",
    "            row[\"code\"])\n",
    "\n",
    "        current_window = row[\"code\"][begin_index: variable_indices[0]] + mask_token + row[\"code\"][\n",
    "                                                                                      variable_indices[1]: end_index]\n",
    "        windows.append(current_window)\n",
    "\n",
    "        if testing:\n",
    "            print(current_window)\n",
    "            print(\"--------\")\n",
    "    return windows\n",
    "\n",
    "\n",
    "def mask_prediction(row, top_k, unmasker, top_k_connection, mask_token, window_size):\n",
    "    \"\"\"\n",
    "    Generates the prediction to the given masked code. If top_k is bigger than 1, then the top_k predictions\n",
    "    will be concatenated by the given top_k_connection. Each prediction(s) will be stripped to remove unnecessary whitespaces.\n",
    "    \"\"\"\n",
    "    mask_num = len(row[\"variable_indices\"])\n",
    "    predictions = list()\n",
    "\n",
    "    if mask_num == 0:\n",
    "        return predictions\n",
    "\n",
    "    else:\n",
    "        windows = split_into_windows(row, window_size, mask_token)\n",
    "        for window in windows:\n",
    "            output = unmasker(window, top_k=top_k)\n",
    "            candidate_concat = top_k_connection.join([candidate['token_str'].strip() for candidate in output])\n",
    "            predictions.append(candidate_concat)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
