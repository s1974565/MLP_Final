{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e7739d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1d97d1",
   "metadata": {},
   "source": [
    "# Tensor <br>\n",
    "Available operations on tensor: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddd5670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7461, 0.4301],\n",
      "        [0.2130, 0.7024]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From list\n",
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "# From numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "# From another tensor\n",
    "x_ones = torch.ones_like(x_data) # retains the properties (shape) of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "# overrides the datatype of x_data\n",
    "# Similar to numpy array, a tensor can only store one datatype\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b12b1ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.2559, 0.1310, 0.2616, 0.7853, 0.4982],\n",
      "        [0.7821, 0.5470, 0.5181, 0.2816, 0.4131],\n",
      "        [0.2964, 0.9288, 0.3784, 0.7883, 0.1867],\n",
      "        [0.4313, 0.3456, 0.7428, 0.9563, 0.9633]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (4, 5)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "277a3910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "CPU tensor is stored on: cpu\n",
      "It is sent to: cuda:0\n",
      "It is sent back to: cpu\n"
     ]
    }
   ],
   "source": [
    "# Attributes of a tensor\n",
    "\n",
    "# By default, tensors are created on the CPU\n",
    "# Copying large tensors across devices can be expensive in terms of time and memory\n",
    "# Typically, CPU memory is larger than GPU memory\n",
    "tensor_cpu = torch.rand(3, 4)\n",
    "tensor_gpu = tensor_cpu.to(\"cuda\")\n",
    "tensor_back_to_cpu = tensor_gpu.to(\"cpu\")\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"CPU tensor is stored on: {tensor_cpu.device}\")\n",
    "print(f\"It is sent to: {tensor_gpu.device}\")\n",
    "print(f\"It is sent back to: {tensor_back_to_cpu.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7c8560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# A lot of tensor operations are identical to Numpy array operations\n",
    "\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[:, -1]}\")\n",
    "\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "caad1046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Joining tensors\n",
    "\n",
    "print(torch.cat([tensor, tensor, tensor], dim=0)) # Concatenating along the row\n",
    "print(torch.cat([tensor, tensor, tensor], dim=1)) # Concatenating along the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52bc6ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning the original function\n",
      "Inside of the original function\n",
      "Ending the original function\n",
      "Beginning the original function\n",
      "Inside of the original function\n",
      "Ending the original function\n"
     ]
    }
   ],
   "source": [
    "# Python decorator examples\n",
    "\n",
    "def tracer_1(function):\n",
    "    def extra_function():\n",
    "        print(\"Beginning the original function\")\n",
    "        function()\n",
    "        print(\"Ending the original function\")\n",
    "    return extra_function\n",
    "\n",
    "def tracer_2(function):\n",
    "    def extra_function():\n",
    "        print(\"Beginning the original function\")\n",
    "        function()\n",
    "        print(\"Ending the original function\")\n",
    "    return extra_function()\n",
    "\n",
    "def original_function():\n",
    "    print(\"Inside of the original function\")\n",
    "    \n",
    "# Equivalent to: tracer_1(original_function)()\n",
    "decorated_function = tracer_1(original_function)\n",
    "decorated_function()\n",
    "\n",
    "tracer_2(original_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eb896f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside decorator\n",
      "Inside inner function\n",
      "Decorated the function\n",
      "Arguments: ()\n",
      "Keyword arguments: {}\n",
      "Inside actual function\n"
     ]
    }
   ],
   "source": [
    "# Decorator with arguments\n",
    "\n",
    "def decorator_fun(func):\n",
    "    print(\"Inside decorator\")\n",
    "    def inner(*args, **kwargs):\n",
    "        print(\"Inside inner function\")\n",
    "        print(\"Decorated the function\")\n",
    "        print(\"Arguments:\", args)\n",
    "        print(\"Keyword arguments:\", kwargs)\n",
    "        func()\n",
    "    return inner\n",
    "\n",
    "# Equivalent to: decorator_fun(func_to)()\n",
    "@decorator_fun\n",
    "def func_to_1():\n",
    "    print(\"Inside actual function\")\n",
    "    \n",
    "func_to_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6fd5a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside decorator\n",
      "Inside inner function\n",
      "Decorated the function\n",
      "Arguments: (1, 2, 3)\n",
      "Keyword arguments: {}\n",
      "Inside actual function\n"
     ]
    }
   ],
   "source": [
    "def func_to_2():\n",
    "    print(\"Inside actual function\")\n",
    "\n",
    "decorator_fun(func_to_2)(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e989236f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "\n",
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea1472e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4245, 0.8693, 0.6016, 0.9920, 0.7234],\n",
      "        [0.9105, 1.6117, 1.0944, 1.6773, 1.5853],\n",
      "        [0.9123, 0.7907, 0.5330, 1.4483, 0.6869],\n",
      "        [1.1653, 1.3335, 1.3034, 1.8494, 1.0877],\n",
      "        [0.6791, 0.7024, 0.6373, 1.0058, 0.6182]])\n",
      "tensor([[0.1590, 0.1581, 0.0082, 0.1257, 0.0944],\n",
      "        [0.0047, 0.9236, 0.3204, 0.0192, 0.4786],\n",
      "        [0.5021, 0.3171, 0.0287, 0.1346, 0.2048],\n",
      "        [0.0407, 0.2326, 0.4602, 0.4271, 0.0782],\n",
      "        [0.1350, 0.0011, 0.2995, 0.0250, 0.0209]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor_1 = torch.rand((5, 5))\n",
    "my_tensor_2 = torch.rand((5, 5))\n",
    "\n",
    "print(my_tensor_1.matmul(my_tensor_2))\n",
    "print(my_tensor_1.mul(my_tensor_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6395195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Single-element tensors If you have a one-element tensor, for example by aggregating all values of a tensor \n",
    "# into one value, you can convert it to a Python numerical value using item():\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))\n",
    "print(type(agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73018d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# In-place operations are denoted by a _ suffix\n",
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46d7cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# This operation returns the result tensor, not modifying the given one.\n",
    "tensor.add(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d80aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors on the CPU and NumPy arrays can share their underlying memory locations, \n",
    "# and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ecfc2924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d333b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# A change in the tensor reflects in the NumPy array.\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "405a81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9359f87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "639ac71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 7. 7. 7. 7.]\n"
     ]
    }
   ],
   "source": [
    "# As they share the same memory, changing the tensor also changes the numpy (and vice versa)\n",
    "t.add_(5)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9448a",
   "metadata": {},
   "source": [
    "# Datasets & Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beea972",
   "metadata": {},
   "source": [
    "We load the FashionMNIST Dataset with the following parameters:\n",
    "\n",
    "        root is the path where the train/test data is stored,\n",
    "\n",
    "        train specifies training or test dataset,\n",
    "\n",
    "        download=True downloads the data from the internet if it’s not available at root.\n",
    "\n",
    "        transform and target_transform specify the feature and label transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c01b962",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dff52b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # Random index\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b544434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image, label = training_data[0]\n",
    "print(type(image), image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "94e7fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom dataset for my files (for image files)\n",
    "# A custom Dataset class must implement three functions: __init__, __len__, and __getitem__\n",
    "\n",
    "# The __init__ function is run once when instantiating the Dataset object. \n",
    "# We initialize the directory containing the images, the annotations file, and both transforms\n",
    "\n",
    "# The __getitem__ function loads and returns a sample from the dataset at the given index idx. \n",
    "# Based on the index, it identifies the image’s location on disk, converts that to a tensor using read_image, \n",
    "# retrieves the corresponding label from the csv data in self.img_labels, \n",
    "# calls the transform functions on them (if applicable), and returns the tensor image and corresponding label in a tuple.\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "96c9aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader is an iterable \n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f84298",
   "metadata": {},
   "source": [
    "We have loaded that dataset into the DataLoader and can iterate through the dataset as needed. Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "659f8e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a2cd2704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "# squeeze() -> Returns a tensor with all the dimensions of input of size 1 removed\n",
    "# The returned tensor shares the same memory space with the input tensor\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef91815",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f224c6",
   "metadata": {},
   "source": [
    "All TorchVision datasets have two parameters -transform to modify the features and target_transform to modify the labels - that accept callables containing the transformation logic. The torchvision.transforms module offers several commonly-used transforms out of the box.\n",
    "\n",
    "The FashionMNIST features are in PIL Image format, and the labels are integers. For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors. To make these transformations, we use ToTensor and Lambda.\n",
    "\n",
    "scatter_() -> https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_ <br>\n",
    "Tensor.scatter_(dim, index, src, reduce=None) → Tensor <br>\n",
    "When dim = 0, then the source values will stay in their original columns (and heights, etc), but move to a different row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b2ef471e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = 3\n",
    "lambda_func = lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)\n",
    "lambda_func(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0b5dd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fee4b",
   "metadata": {},
   "source": [
    "# Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6c1b61ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our neural network by subclassing nn.Module, and initialize the neural network layers in __init__. \n",
    "# Every nn.Module subclass implements the operations on input data in the forward method.\n",
    "\n",
    "# nn.Sequential is an ordered container of modules. Check the following for more details.\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "46358610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# We create an instance of NeuralNetwork, and move it to the device, and print its structure.\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ffeee",
   "metadata": {},
   "source": [
    "To use the model, we pass it the input data. This executes the model’s forward, along with some background operations. Do not call model.forward() directly!\n",
    "\n",
    "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the nn.Softmax module. <br>\n",
    "Rows: Each image / Columns: output values to the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "61433ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Generating two random images\n",
    "X = torch.rand(2, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e510db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0885,  0.0425,  0.0292, -0.0655, -0.0576, -0.0184, -0.0579, -0.0769,\n",
       "         -0.1545,  0.0230],\n",
       "        [ 0.0371,  0.0602,  0.0031, -0.0621, -0.0516, -0.0353, -0.0292, -0.0472,\n",
       "         -0.1117, -0.0803]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "62aa9366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1117, 0.1067, 0.1053, 0.0958, 0.0966, 0.1004, 0.0965, 0.0947, 0.0876,\n",
       "         0.1047],\n",
       "        [0.1070, 0.1095, 0.1034, 0.0969, 0.0979, 0.0995, 0.1001, 0.0983, 0.0922,\n",
       "         0.0951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce874bb",
   "metadata": {},
   "source": [
    "# Automatic Differentiation with torch.autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc1014b",
   "metadata": {},
   "source": [
    "When training neural networks, the most frequently used algorithm is back propagation. In this algorithm, parameters (model weights) are adjusted according to the gradient of the loss function with respect to the given parameter.\n",
    "\n",
    "To compute those gradients, PyTorch has a built-in differentiation engine called torch.autograd. It supports automatic computation of gradient for any computational graph.\n",
    "\n",
    "Consider the simplest one-layer neural network, with input x, parameters w and b, and some loss function. It can be defined in PyTorch in the following manner:\n",
    "\n",
    "Full article: https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c8460afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set the value of requires_grad when creating a tensor, or later by using x.requires_grad_(True) method.\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "\n",
    "# Matrix multiplication\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ebbbd7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4577, -4.1315,  6.4695], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3e93ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x000001BC0FD16AD0>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x000001BC0FCD28C0>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d04f55",
   "metadata": {},
   "source": [
    "We can only obtain the grad properties for the leaf nodes of the computational graph, which have requires_grad property set to True. For all other nodes in our graph, gradients will not be available.\n",
    "\n",
    "We can only perform gradient calculations using backward once on a given graph, for performance reasons. If we need to do several backward calls on the same graph, we need to pass retain_graph=True to the backward call. Otherwise it will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8012bb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1292, 0.0053, 0.3328],\n",
      "        [0.1292, 0.0053, 0.3328],\n",
      "        [0.1292, 0.0053, 0.3328],\n",
      "        [0.1292, 0.0053, 0.3328],\n",
      "        [0.1292, 0.0053, 0.3328]])\n",
      "tensor([0.1292, 0.0053, 0.3328])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "60b70285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [142], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(w\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(b\u001b[38;5;241m.\u001b[39mgrad)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlp\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\mlp\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# Throws an error, as it is (by default) not possible to backtrack twice for a graph.\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06187bf8",
   "metadata": {},
   "source": [
    "Disabling Gradient Tracking\n",
    "\n",
    "By default, all tensors with requires_grad=True are tracking their computational history and support gradient computation. However, there are some cases when we do not need to do that, for example, when we have trained the model and just want to apply it to some input data, i.e. we only want to do forward computations through the network. We can stop tracking computations by surrounding our computation code with torch.no_grad() block:\n",
    "\n",
    "\n",
    "There are reasons you might want to disable gradient tracking:\n",
    "\n",
    "1. To mark some parameters in your neural network as frozen parameters.\n",
    "2. To speed up computations when you are only doing forward pass, because computations on tensors that do not track gradients would be more efficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bcaa9b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b4ec0",
   "metadata": {},
   "source": [
    "Another way to achieve the same result is to use the detach() method on the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3a9bf03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w) + b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710bc7bb",
   "metadata": {},
   "source": [
    "More on Computational Graphs\n",
    "\n",
    "Conceptually, autograd keeps a record of data (tensors) and all executed operations (along with the resulting new tensors) in a directed acyclic graph (DAG) consisting of Function objects. In this DAG, leaves are the input tensors, roots are the output tensors. By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule.\n",
    "\n",
    "In a forward pass, autograd does two things simultaneously:\n",
    "\n",
    "1. run the requested operation to compute a resulting tensor\n",
    "2. maintain the operation’s gradient function in the DAG.\n",
    "\n",
    "The backward pass kicks off when .backward() is called on the DAG root. autograd then:\n",
    "\n",
    "1. computes the gradients from each .grad_fn,\n",
    "2. accumulates them in the respective tensor’s .grad attribute\n",
    "3. using the chain rule, propagates all the way to the leaf tensors.\n",
    "\n",
    "Note\n",
    "\n",
    "DAGs are dynamic in PyTorch. An important thing to note is that the graph is recreated from scratch; after each .backward() call, autograd starts populating a new graph. This is exactly what allows you to use control flow statements in your model; you can change the shape, size and operations at every iteration if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c563e3",
   "metadata": {},
   "source": [
    "# Optimizing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "42e66b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-defining previous codes, for readability\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f6395000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63043c07",
   "metadata": {},
   "source": [
    "Once we set our hyperparameters, we can then train and optimize our model with an optimization loop. Each iteration of the optimization loop is called an epoch.\n",
    "\n",
    "Each epoch consists of two main parts:\n",
    "\n",
    "1. The Train Loop - iterate over the training dataset and try to converge to optimal parameters.\n",
    "2. The Validation/Test Loop - iterate over the test dataset to check if model performance is improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "95242385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0526da1",
   "metadata": {},
   "source": [
    "Optimization is the process of adjusting model parameters to reduce model error in each training step. Optimization algorithms define how this process is performed (in this example we use Stochastic Gradient Descent). All optimization logic is encapsulated in the optimizer object. Here, we use the SGD optimizer; additionally, there are many different optimizers available in PyTorch such as ADAM and RMSProp, that work better for different kinds of models and data.\n",
    "\n",
    "We initialize the optimizer by registering the model’s parameters that need to be trained, and passing in the learning rate hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0b3cb1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8b2fe",
   "metadata": {},
   "source": [
    "Inside the training loop, optimization happens in three steps:\n",
    "\n",
    "1. Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "2. Backpropagate the prediction loss with a call to loss.backward(). PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "3. Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4e8339e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f47d2b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d87ab782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937.5"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "461f31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        \n",
    "        # Removing the gradient calculated from the previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Calculating the gradients of the parameters, and save the gradients to parameter tensors\n",
    "        loss.backward()\n",
    "        # Updating the parameters; the parameters were directly registered to the optimiser\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# The testing results do not affect the training; the training is only based on the training set\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # We do not need to calculate the gradients for testing; we only do forward pass\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9c002f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302521  [   64/60000]\n",
      "loss: 2.284610  [ 6464/60000]\n",
      "loss: 2.264922  [12864/60000]\n",
      "loss: 2.267855  [19264/60000]\n",
      "loss: 2.248837  [25664/60000]\n",
      "loss: 2.217931  [32064/60000]\n",
      "loss: 2.235855  [38464/60000]\n",
      "loss: 2.191453  [44864/60000]\n",
      "loss: 2.187317  [51264/60000]\n",
      "loss: 2.158524  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 2.152836 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.159380  [   64/60000]\n",
      "loss: 2.143841  [ 6464/60000]\n",
      "loss: 2.087281  [12864/60000]\n",
      "loss: 2.110425  [19264/60000]\n",
      "loss: 2.053046  [25664/60000]\n",
      "loss: 1.995906  [32064/60000]\n",
      "loss: 2.026127  [38464/60000]\n",
      "loss: 1.940389  [44864/60000]\n",
      "loss: 1.946012  [51264/60000]\n",
      "loss: 1.872364  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.8%, Avg loss: 1.870565 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.902324  [   64/60000]\n",
      "loss: 1.865633  [ 6464/60000]\n",
      "loss: 1.750605  [12864/60000]\n",
      "loss: 1.801267  [19264/60000]\n",
      "loss: 1.688998  [25664/60000]\n",
      "loss: 1.641328  [32064/60000]\n",
      "loss: 1.670128  [38464/60000]\n",
      "loss: 1.569309  [44864/60000]\n",
      "loss: 1.594446  [51264/60000]\n",
      "loss: 1.489701  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.507959 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.570192  [   64/60000]\n",
      "loss: 1.535001  [ 6464/60000]\n",
      "loss: 1.390321  [12864/60000]\n",
      "loss: 1.473035  [19264/60000]\n",
      "loss: 1.357506  [25664/60000]\n",
      "loss: 1.345004  [32064/60000]\n",
      "loss: 1.370519  [38464/60000]\n",
      "loss: 1.290296  [44864/60000]\n",
      "loss: 1.323351  [51264/60000]\n",
      "loss: 1.223774  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.250185 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.318355  [   64/60000]\n",
      "loss: 1.303863  [ 6464/60000]\n",
      "loss: 1.141290  [12864/60000]\n",
      "loss: 1.257136  [19264/60000]\n",
      "loss: 1.139819  [25664/60000]\n",
      "loss: 1.149279  [32064/60000]\n",
      "loss: 1.182408  [38464/60000]\n",
      "loss: 1.112219  [44864/60000]\n",
      "loss: 1.150996  [51264/60000]\n",
      "loss: 1.061944  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.086802 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.147971  [   64/60000]\n",
      "loss: 1.155049  [ 6464/60000]\n",
      "loss: 0.973719  [12864/60000]\n",
      "loss: 1.117370  [19264/60000]\n",
      "loss: 1.002520  [25664/60000]\n",
      "loss: 1.015948  [32064/60000]\n",
      "loss: 1.062477  [38464/60000]\n",
      "loss: 0.995735  [44864/60000]\n",
      "loss: 1.036869  [51264/60000]\n",
      "loss: 0.958004  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.979918 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.028218  [   64/60000]\n",
      "loss: 1.057263  [ 6464/60000]\n",
      "loss: 0.857550  [12864/60000]\n",
      "loss: 1.022334  [19264/60000]\n",
      "loss: 0.915039  [25664/60000]\n",
      "loss: 0.922161  [32064/60000]\n",
      "loss: 0.982835  [38464/60000]\n",
      "loss: 0.919064  [44864/60000]\n",
      "loss: 0.958654  [51264/60000]\n",
      "loss: 0.888045  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.907218 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.940344  [   64/60000]\n",
      "loss: 0.989564  [ 6464/60000]\n",
      "loss: 0.774922  [12864/60000]\n",
      "loss: 0.955202  [19264/60000]\n",
      "loss: 0.856943  [25664/60000]\n",
      "loss: 0.854131  [32064/60000]\n",
      "loss: 0.927026  [38464/60000]\n",
      "loss: 0.868032  [44864/60000]\n",
      "loss: 0.903337  [51264/60000]\n",
      "loss: 0.838167  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.855395 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.873691  [   64/60000]\n",
      "loss: 0.939199  [ 6464/60000]\n",
      "loss: 0.713826  [12864/60000]\n",
      "loss: 0.905776  [19264/60000]\n",
      "loss: 0.815789  [25664/60000]\n",
      "loss: 0.803472  [32064/60000]\n",
      "loss: 0.884920  [38464/60000]\n",
      "loss: 0.832802  [44864/60000]\n",
      "loss: 0.862368  [51264/60000]\n",
      "loss: 0.800426  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.1%, Avg loss: 0.816390 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.820764  [   64/60000]\n",
      "loss: 0.898932  [ 6464/60000]\n",
      "loss: 0.666715  [12864/60000]\n",
      "loss: 0.867821  [19264/60000]\n",
      "loss: 0.784327  [25664/60000]\n",
      "loss: 0.764590  [32064/60000]\n",
      "loss: 0.850962  [38464/60000]\n",
      "loss: 0.806766  [44864/60000]\n",
      "loss: 0.831034  [51264/60000]\n",
      "loss: 0.770378  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.785512 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf57d8",
   "metadata": {},
   "source": [
    "# Save and Load the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ba3c7",
   "metadata": {},
   "source": [
    "Check: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d858f7",
   "metadata": {},
   "source": [
    "# Training a model (QuickStart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36099a20",
   "metadata": {},
   "source": [
    "If you are already familiar with other deep learning frameworks, then you may only need to check this section to get a brief idea about the Pytorch pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec6ba5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f9e852b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
      "        2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "# Here we define a batch size of 64, i.e. each element in the dataloader iterable will \n",
    "# return a batch of 64 features and labels.\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec71741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in test_dataloader:\n",
    "    sns.heatmap(X[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fb5ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# To define a neural network in PyTorch, we create a class that inherits from nn.Module. \n",
    "# We define the layers of the network in the __init__ function and specify how data will pass through \n",
    "# the network in the forward function. To accelerate operations in the neural network, we move it to the GPU if available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# Loading the model to the GPU's memory\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13200b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3693d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025dad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a14ce6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a single training loop, the model makes predictions on the training dataset (fed to it in batches), \n",
    "# and backpropagates the prediction error to adjust the model’s parameters.\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d89b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "543b1db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307534  [   64/60000]\n",
      "loss: 2.167217  [ 6464/60000]\n",
      "loss: 1.840225  [12864/60000]\n",
      "loss: 1.553537  [19264/60000]\n",
      "loss: 1.183067  [25664/60000]\n",
      "loss: 1.071244  [32064/60000]\n",
      "loss: 0.998889  [38464/60000]\n",
      "loss: 0.878722  [44864/60000]\n",
      "loss: 0.866610  [51264/60000]\n",
      "loss: 0.801363  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.2%, Avg loss: 0.798577 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.810939  [   64/60000]\n",
      "loss: 0.855113  [ 6464/60000]\n",
      "loss: 0.594799  [12864/60000]\n",
      "loss: 0.816536  [19264/60000]\n",
      "loss: 0.677616  [25664/60000]\n",
      "loss: 0.633795  [32064/60000]\n",
      "loss: 0.695376  [38464/60000]\n",
      "loss: 0.685091  [44864/60000]\n",
      "loss: 0.683371  [51264/60000]\n",
      "loss: 0.628821  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.629350 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.558824  [   64/60000]\n",
      "loss: 0.660280  [ 6464/60000]\n",
      "loss: 0.434663  [12864/60000]\n",
      "loss: 0.697811  [19264/60000]\n",
      "loss: 0.590250  [25664/60000]\n",
      "loss: 0.549186  [32064/60000]\n",
      "loss: 0.579904  [38464/60000]\n",
      "loss: 0.661774  [44864/60000]\n",
      "loss: 0.646773  [51264/60000]\n",
      "loss: 0.535706  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.5%, Avg loss: 0.557493 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.451372  [   64/60000]\n",
      "loss: 0.573400  [ 6464/60000]\n",
      "loss: 0.371598  [12864/60000]\n",
      "loss: 0.634052  [19264/60000]\n",
      "loss: 0.540007  [25664/60000]\n",
      "loss: 0.506184  [32064/60000]\n",
      "loss: 0.525678  [38464/60000]\n",
      "loss: 0.681945  [44864/60000]\n",
      "loss: 0.631691  [51264/60000]\n",
      "loss: 0.467891  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.521770 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.390348  [   64/60000]\n",
      "loss: 0.531124  [ 6464/60000]\n",
      "loss: 0.338566  [12864/60000]\n",
      "loss: 0.592142  [19264/60000]\n",
      "loss: 0.496580  [25664/60000]\n",
      "loss: 0.480078  [32064/60000]\n",
      "loss: 0.493924  [38464/60000]\n",
      "loss: 0.688851  [44864/60000]\n",
      "loss: 0.613137  [51264/60000]\n",
      "loss: 0.425555  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.500382 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "eff37e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슈퍼인공지능문어다녀감\n"
     ]
    }
   ],
   "source": [
    "print(\"슈퍼인공지능문어다녀감\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "552e9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평범한공룡인형도다녀감\n"
     ]
    }
   ],
   "source": [
    "print(\"평범한공룡인형도다녀감\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "149b3848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼색고양이나나도다녀감\n"
     ]
    }
   ],
   "source": [
    "print(\"삼색고양이나나도다녀감\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f7a2d30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검은고양이자자도다녀감\n"
     ]
    }
   ],
   "source": [
    "print(\"검은고양이자자도다녀감\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd6fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
