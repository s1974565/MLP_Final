{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "# Helpers\n",
    "from testing import *\n",
    "# Baseline model 1\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, pipeline\n",
    "# Sentence similarity model\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Check if GPU acceleration is available\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    device_num = torch.cuda.current_device()\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    device_num = -1\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Run this if you removed pickle files\n",
    "# saving_pickles()\n",
    "\n",
    "train_df, valid_df, test_df = loading_pickles()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Constants (for training) -------------------------------------------------------------------------------------------------\n",
    "\n",
    "mask_prob = 0.5\n",
    "window_size = 100\n",
    "# For training (not validation)\n",
    "batch_size = 50\n",
    "\n",
    "# Whether to shuffle the training set or not\n",
    "shuffle = False\n",
    "# Changing this may lead to different masking result. Do not change unless necessary.\n",
    "rng_seed = 42\n",
    "\n",
    "# Using only a portion of the train dataset for performance\n",
    "# Set it to 1 to use all train dataset; increasing this may give better result.\n",
    "size_limit_proportion_train = 0.01\n",
    "\n",
    "# For validation set. Do not change unless necessary\n",
    "size_limit_proportion_valid = 0.5\n",
    "\n",
    "# Hyperparameters ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "total_epoch_number = 2\n",
    "# Initial learning rate for the optimizer\n",
    "learning_rate = 0.00005\n",
    "weight_decay_coefficient = 0.01"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Masking:   0%|          | 0/4121 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff921a94dccb45d2a8eedb6353ba526f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Window split:   0%|          | 0/4121 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "416f94abbd2d48069f6cef2cda5235a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Masking:   0%|          | 0/23107 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7e39ccd30b24f64813606139e05ef84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Masking:   0%|          | 0/22176 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "764e24c6868748e7afdcb2d01ba89e19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def masking_df(code_df):\n",
    "    masked_code_df = mask_variable_df(code_df, mask_prob=mask_prob, rng_seed=rng_seed)\n",
    "    merged_code_df = pd.concat([code_df, masked_code_df], axis=\"columns\")\n",
    "    return merged_code_df\n",
    "\n",
    "def window_df(code_df):\n",
    "    merged_code_df = masking_df(code_df)\n",
    "    return split_into_windows(merged_code_df, window_size=window_size, mask_token=\"<mask>\")\n",
    "\n",
    "train_df_size = int(len(train_df) * size_limit_proportion_train)\n",
    "valid_df_size = int(len(valid_df) * size_limit_proportion_valid)\n",
    "\n",
    "if shuffle:\n",
    "    train_df = train_df.sample(frac=1, random_state=rng_seed).reset_index(drop=True)\n",
    "\n",
    "window_train_df = window_df(train_df[:train_df_size])\n",
    "\n",
    "merged_valid_df = masking_df(valid_df[:valid_df_size])\n",
    "merged_test_df = masking_df(test_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "three ways to fine tune the model:\n",
    "1. Fine-tune the last head of the model <- Current approach\n",
    "2. Fine-tune the whole model\n",
    "3. Add extra layers to the model and fine tune the additional layer\n",
    "\n",
    "We use the first baseline model, as it showed the better performance in testing.\n",
    "See the baseline_testing notebook for more details.\n",
    "\n",
    "There are three main hyperparameters: total_epoch_number, learning_rate, and weight_decay_coefficient\n",
    "Try different combinations to fine the best performing model. I commented thoroughly so there should be no problem in understanding the codes.\n",
    "If you want to change the optimizer, then you need to directly edit the optimizer definition in the training loop cell.\n",
    "\n",
    "After a model is fine-tuned, its performance will then be evaluated based on the average cosine similarity with the validaion set.\n",
    "You can check if the fine-tuned model performs better or worse compared to the baseline model. If your model performs well, then\n",
    "consider saving the model so that we can use it later. For performance, it is set to only use the half of the validation set.\n",
    "\n",
    "If any error occurs, or if you have a suggestion, let me know.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model investigation\n",
    "\n",
    "You need to uncomment some cells to see the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# All Huggingface models are standard torch.nn.Module, so they can easily be used in any training loop.\n",
    "\n",
    "# Model architecture information:\n",
    "# https://huggingface.co/docs/transformers/v4.27.2/en/model_doc/roberta#transformers.RobertaForMaskedLM\n",
    "model_b1 = RobertaForMaskedLM.from_pretrained('microsoft/codebert-base-mlm')\n",
    "tokenizer_b1 = RobertaTokenizer.from_pretrained('microsoft/codebert-base-mlm')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Model structure (Uncomment to see)\n",
    "# print(model_b1)\n",
    "\n",
    "# Embedding size = (50265, 768)\n",
    "# Dropout probability = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Model parameters (Uncomment to see)\n",
    "\n",
    "# for name, param in model_b1.named_parameters():\n",
    "#     print(name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight False\n",
      "roberta.embeddings.position_embeddings.weight False\n",
      "roberta.embeddings.token_type_embeddings.weight False\n",
      "roberta.embeddings.LayerNorm.weight False\n",
      "roberta.embeddings.LayerNorm.bias False\n",
      "roberta.encoder.layer.0.attention.self.query.weight False\n",
      "roberta.encoder.layer.0.attention.self.query.bias False\n",
      "roberta.encoder.layer.0.attention.self.key.weight False\n",
      "roberta.encoder.layer.0.attention.self.key.bias False\n",
      "roberta.encoder.layer.0.attention.self.value.weight False\n",
      "roberta.encoder.layer.0.attention.self.value.bias False\n",
      "roberta.encoder.layer.0.attention.output.dense.weight False\n",
      "roberta.encoder.layer.0.attention.output.dense.bias False\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.0.intermediate.dense.weight False\n",
      "roberta.encoder.layer.0.intermediate.dense.bias False\n",
      "roberta.encoder.layer.0.output.dense.weight False\n",
      "roberta.encoder.layer.0.output.dense.bias False\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.1.attention.self.query.weight False\n",
      "roberta.encoder.layer.1.attention.self.query.bias False\n",
      "roberta.encoder.layer.1.attention.self.key.weight False\n",
      "roberta.encoder.layer.1.attention.self.key.bias False\n",
      "roberta.encoder.layer.1.attention.self.value.weight False\n",
      "roberta.encoder.layer.1.attention.self.value.bias False\n",
      "roberta.encoder.layer.1.attention.output.dense.weight False\n",
      "roberta.encoder.layer.1.attention.output.dense.bias False\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.1.intermediate.dense.weight False\n",
      "roberta.encoder.layer.1.intermediate.dense.bias False\n",
      "roberta.encoder.layer.1.output.dense.weight False\n",
      "roberta.encoder.layer.1.output.dense.bias False\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.2.attention.self.query.weight False\n",
      "roberta.encoder.layer.2.attention.self.query.bias False\n",
      "roberta.encoder.layer.2.attention.self.key.weight False\n",
      "roberta.encoder.layer.2.attention.self.key.bias False\n",
      "roberta.encoder.layer.2.attention.self.value.weight False\n",
      "roberta.encoder.layer.2.attention.self.value.bias False\n",
      "roberta.encoder.layer.2.attention.output.dense.weight False\n",
      "roberta.encoder.layer.2.attention.output.dense.bias False\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.2.intermediate.dense.weight False\n",
      "roberta.encoder.layer.2.intermediate.dense.bias False\n",
      "roberta.encoder.layer.2.output.dense.weight False\n",
      "roberta.encoder.layer.2.output.dense.bias False\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.3.attention.self.query.weight False\n",
      "roberta.encoder.layer.3.attention.self.query.bias False\n",
      "roberta.encoder.layer.3.attention.self.key.weight False\n",
      "roberta.encoder.layer.3.attention.self.key.bias False\n",
      "roberta.encoder.layer.3.attention.self.value.weight False\n",
      "roberta.encoder.layer.3.attention.self.value.bias False\n",
      "roberta.encoder.layer.3.attention.output.dense.weight False\n",
      "roberta.encoder.layer.3.attention.output.dense.bias False\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.3.intermediate.dense.weight False\n",
      "roberta.encoder.layer.3.intermediate.dense.bias False\n",
      "roberta.encoder.layer.3.output.dense.weight False\n",
      "roberta.encoder.layer.3.output.dense.bias False\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.4.attention.self.query.weight False\n",
      "roberta.encoder.layer.4.attention.self.query.bias False\n",
      "roberta.encoder.layer.4.attention.self.key.weight False\n",
      "roberta.encoder.layer.4.attention.self.key.bias False\n",
      "roberta.encoder.layer.4.attention.self.value.weight False\n",
      "roberta.encoder.layer.4.attention.self.value.bias False\n",
      "roberta.encoder.layer.4.attention.output.dense.weight False\n",
      "roberta.encoder.layer.4.attention.output.dense.bias False\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.4.intermediate.dense.weight False\n",
      "roberta.encoder.layer.4.intermediate.dense.bias False\n",
      "roberta.encoder.layer.4.output.dense.weight False\n",
      "roberta.encoder.layer.4.output.dense.bias False\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.5.attention.self.query.weight False\n",
      "roberta.encoder.layer.5.attention.self.query.bias False\n",
      "roberta.encoder.layer.5.attention.self.key.weight False\n",
      "roberta.encoder.layer.5.attention.self.key.bias False\n",
      "roberta.encoder.layer.5.attention.self.value.weight False\n",
      "roberta.encoder.layer.5.attention.self.value.bias False\n",
      "roberta.encoder.layer.5.attention.output.dense.weight False\n",
      "roberta.encoder.layer.5.attention.output.dense.bias False\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.5.intermediate.dense.weight False\n",
      "roberta.encoder.layer.5.intermediate.dense.bias False\n",
      "roberta.encoder.layer.5.output.dense.weight False\n",
      "roberta.encoder.layer.5.output.dense.bias False\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.6.attention.self.query.weight False\n",
      "roberta.encoder.layer.6.attention.self.query.bias False\n",
      "roberta.encoder.layer.6.attention.self.key.weight False\n",
      "roberta.encoder.layer.6.attention.self.key.bias False\n",
      "roberta.encoder.layer.6.attention.self.value.weight False\n",
      "roberta.encoder.layer.6.attention.self.value.bias False\n",
      "roberta.encoder.layer.6.attention.output.dense.weight False\n",
      "roberta.encoder.layer.6.attention.output.dense.bias False\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.6.intermediate.dense.weight False\n",
      "roberta.encoder.layer.6.intermediate.dense.bias False\n",
      "roberta.encoder.layer.6.output.dense.weight False\n",
      "roberta.encoder.layer.6.output.dense.bias False\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.7.attention.self.query.weight False\n",
      "roberta.encoder.layer.7.attention.self.query.bias False\n",
      "roberta.encoder.layer.7.attention.self.key.weight False\n",
      "roberta.encoder.layer.7.attention.self.key.bias False\n",
      "roberta.encoder.layer.7.attention.self.value.weight False\n",
      "roberta.encoder.layer.7.attention.self.value.bias False\n",
      "roberta.encoder.layer.7.attention.output.dense.weight False\n",
      "roberta.encoder.layer.7.attention.output.dense.bias False\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.7.intermediate.dense.weight False\n",
      "roberta.encoder.layer.7.intermediate.dense.bias False\n",
      "roberta.encoder.layer.7.output.dense.weight False\n",
      "roberta.encoder.layer.7.output.dense.bias False\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.8.attention.self.query.weight False\n",
      "roberta.encoder.layer.8.attention.self.query.bias False\n",
      "roberta.encoder.layer.8.attention.self.key.weight False\n",
      "roberta.encoder.layer.8.attention.self.key.bias False\n",
      "roberta.encoder.layer.8.attention.self.value.weight False\n",
      "roberta.encoder.layer.8.attention.self.value.bias False\n",
      "roberta.encoder.layer.8.attention.output.dense.weight False\n",
      "roberta.encoder.layer.8.attention.output.dense.bias False\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.8.intermediate.dense.weight False\n",
      "roberta.encoder.layer.8.intermediate.dense.bias False\n",
      "roberta.encoder.layer.8.output.dense.weight False\n",
      "roberta.encoder.layer.8.output.dense.bias False\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.9.attention.self.query.weight False\n",
      "roberta.encoder.layer.9.attention.self.query.bias False\n",
      "roberta.encoder.layer.9.attention.self.key.weight False\n",
      "roberta.encoder.layer.9.attention.self.key.bias False\n",
      "roberta.encoder.layer.9.attention.self.value.weight False\n",
      "roberta.encoder.layer.9.attention.self.value.bias False\n",
      "roberta.encoder.layer.9.attention.output.dense.weight False\n",
      "roberta.encoder.layer.9.attention.output.dense.bias False\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.9.intermediate.dense.weight False\n",
      "roberta.encoder.layer.9.intermediate.dense.bias False\n",
      "roberta.encoder.layer.9.output.dense.weight False\n",
      "roberta.encoder.layer.9.output.dense.bias False\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.10.attention.self.query.weight False\n",
      "roberta.encoder.layer.10.attention.self.query.bias False\n",
      "roberta.encoder.layer.10.attention.self.key.weight False\n",
      "roberta.encoder.layer.10.attention.self.key.bias False\n",
      "roberta.encoder.layer.10.attention.self.value.weight False\n",
      "roberta.encoder.layer.10.attention.self.value.bias False\n",
      "roberta.encoder.layer.10.attention.output.dense.weight False\n",
      "roberta.encoder.layer.10.attention.output.dense.bias False\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.10.intermediate.dense.weight False\n",
      "roberta.encoder.layer.10.intermediate.dense.bias False\n",
      "roberta.encoder.layer.10.output.dense.weight False\n",
      "roberta.encoder.layer.10.output.dense.bias False\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.11.attention.self.query.weight False\n",
      "roberta.encoder.layer.11.attention.self.query.bias False\n",
      "roberta.encoder.layer.11.attention.self.key.weight False\n",
      "roberta.encoder.layer.11.attention.self.key.bias False\n",
      "roberta.encoder.layer.11.attention.self.value.weight False\n",
      "roberta.encoder.layer.11.attention.self.value.bias False\n",
      "roberta.encoder.layer.11.attention.output.dense.weight False\n",
      "roberta.encoder.layer.11.attention.output.dense.bias False\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias False\n",
      "roberta.encoder.layer.11.intermediate.dense.weight False\n",
      "roberta.encoder.layer.11.intermediate.dense.bias False\n",
      "roberta.encoder.layer.11.output.dense.weight False\n",
      "roberta.encoder.layer.11.output.dense.bias False\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight False\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias False\n",
      "lm_head.bias True\n",
      "lm_head.dense.weight True\n",
      "lm_head.dense.bias True\n",
      "lm_head.layer_norm.weight True\n",
      "lm_head.layer_norm.bias True\n"
     ]
    }
   ],
   "source": [
    "# Freeze parameters except the last head\n",
    "\n",
    "for name, param in model_b1.named_parameters():\n",
    "    if \"lm_head\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "    print(name, param.requires_grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class CodeNetDataset(Dataset):\n",
    "    def __init__(self, window_df, tokenizer):\n",
    "        self.window_df = window_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_token_id = tokenizer.mask_token_id\n",
    "\n",
    "        # Not sure how to apply tqdm (progress bar) for this; I plan to update soon\n",
    "        self.tokenized = tokenizer(list(window_df[\"window\"]), padding=True)\n",
    "        self.input_ids = self.tokenized[\"input_ids\"]\n",
    "        self.attention_mask = self.tokenized[\"attention_mask\"]\n",
    "        self.label = self.window_df[\"label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.window_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label_token_id = self.tokenizer.convert_tokens_to_ids(self.label[index])\n",
    "        # size is equal to the vocabulary size\n",
    "        one_hot_label = [0] * self.tokenizer.vocab_size\n",
    "        one_hot_label[label_token_id] = 1\n",
    "        mask_token_index = self.input_ids[index].index(self.mask_token_id)\n",
    "\n",
    "        return torch.tensor(self.input_ids[index]), torch.tensor(self.attention_mask[index]), torch.tensor(one_hot_label), mask_token_index\n",
    "\n",
    "train_dataset = CodeNetDataset(window_train_df, tokenizer_b1)\n",
    "valid_dataset = CodeNetDataset(window_valid_df, tokenizer_b1)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "# batch_size = dataset_size (to get the entire dataset at once)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=valid_dataset.__len__())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine-tuning\n",
    "\n",
    "As we are using another sentence embedding model for calculating the cosine similarity, the loss value needs to be backpropagated through the embedding model as well. But it seems infeasible for this moment, so I will going to implement the loss function only on the cross-entropy (perplexity). Also, we only use the top_1 prediction as it showed the best performance in the baseline testing."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Loss function (Softmax + CrossEntropy)\n",
    "# The result values from the model is logits, which cannot be compared with one-hot true labels.\n",
    "# For example, logits varies from the negative infinity to the positive infinity, and the positive infinity is equal to the 100% probability.\n",
    "# But the one-hot true labels has only 0 and 1, and 1 means 100% probability.\n",
    "# So the Softmax will be applied on the logits, before they are compared by the CrossEntropy.\n",
    "def soft_entropy(prediction_logits, one_hot_labels, mask_token_indices):\n",
    "    # Getting the embeddings only for the mask token locations\n",
    "    mask_embedding_list = list()\n",
    "    for row, mask_token_index in zip(range(prediction_logits.shape[0]), mask_token_indices):\n",
    "        # The sliced tensors are single-dimensional vectors. So we need to add a dummy dimension at dim=0\n",
    "        # so that they can be concatenated in dim=0\n",
    "        # For example, if the sliced tensors have the shape [5], torch.unsqueeze() makes it to [1, 5]\n",
    "        mask_embedding = torch.unsqueeze(prediction_logits[row, mask_token_index], 0)\n",
    "        mask_embedding_list.append(mask_embedding)\n",
    "\n",
    "    # Shape = [batch_size, vocabulary_size]\n",
    "    mask_embeddings = torch.cat(mask_embedding_list, dim=0)\n",
    "    probabilities = F.softmax(mask_embeddings, dim=1)\n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    # By default, it returns a single scalar (averaged over batch)\n",
    "    return loss(probabilities, one_hot_labels.float())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Epoch 1:   0%|          | 0/246 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dd528c65dc3432fa6ada543deb41eb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 10.745734214782715\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2:   0%|          | 0/246 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f278cff09cbc4daaa81f972219baae39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 10.72003173828125\n"
     ]
    },
    {
     "data": {
      "text/plain": "RobertaForMaskedLM(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (lm_head): RobertaLMHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n  )\n)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running this cell multiple times in a single notebook can fully saturate the GPU memory, which leads the OutOfMemoryError.\n",
    "# If it happens, re-start the notebook kernel to remove all model instances from the GPU memory.\n",
    "# It seems like the memory error sometimes happens when the dataset size is too big, regardless of the batch size.\n",
    "# I am not sure why it is the case; Let me know if you encounter this issue.\n",
    "\n",
    "# Setting the model to the train mode\n",
    "model_b1.train()\n",
    "model_b1.to(device)\n",
    "\n",
    "# Using the AdamW optimizer: https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html\n",
    "# Feel free to try others\n",
    "optimizer = torch.optim.AdamW(model_b1.parameters(), lr=learning_rate, weight_decay=weight_decay_coefficient)\n",
    "\n",
    "for epoch_num in range(1, total_epoch_number+1):\n",
    "    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch_num}\", total=math.ceil(len(train_dataset) / batch_size)):\n",
    "        # Sending to GPU\n",
    "        batch_input_ids = batch[0].to(device)\n",
    "        batch_attention_mask = batch[1].to(device)\n",
    "        batch_one_hot_label = batch[2].to(device)\n",
    "        batch_mask_token_index = batch[3].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        prediction_logits = model_b1(input_ids=batch_input_ids, attention_mask=batch_attention_mask).logits\n",
    "        # Computing prediction error\n",
    "        loss = soft_entropy(prediction_logits, batch_one_hot_label, batch_mask_token_index)\n",
    "        # Removing gradients from the past iteration\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Removing to free up memory\n",
    "        del batch_input_ids\n",
    "        del batch_attention_mask\n",
    "        del batch_one_hot_label\n",
    "        del batch_mask_token_index\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"Epoch {epoch_num}, Loss: {loss.item()}\")\n",
    "\n",
    "# Setting the model back to the evaluation mode\n",
    "model_b1.eval()\n",
    "# Not to print the model structure\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation (Cosine similarity)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Window split:   0%|          | 0/23107 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34919356a5f54ce49ba37597e5d10d9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Prediction:   0%|          | 0/67804 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d570a2913c64abb99211546476942cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Similarity:   0%|          | 0/67804 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1345900de62c488cbf4fa97917c39858"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b1_finetuned = pipeline('fill-mask', model=model_b1, tokenizer=tokenizer_b1, device=device_num)\n",
    "b1_finetuned_result = model_test(merged_code_df=merged_valid_df, unmasker=b1_finetuned, top_k=1, window_size=window_size, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine similarity: 0.49379345774650574\n",
      "The fine-tuned model performance is better than the baseline, by 0.01018860936164856\n"
     ]
    }
   ],
   "source": [
    "average_similarity = np.mean(b1_finetuned_result['similarity'])\n",
    "# Baseline performance (I plan to send you the result by this evening)\n",
    "baseline_similarity = to_be_confirmed\n",
    "print(f\"Average cosine similarity: {average_similarity}\")\n",
    "if average_similarity < baseline_similarity:\n",
    "    print(f\"The fine-tuned model performance is worse than the baseline, by {baseline_similarity-average_similarity}\")\n",
    "else:\n",
    "    print(f\"The fine-tuned model performance is better than the baseline, by {average_similarity-baseline_similarity}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the model\n",
    "\n",
    "Check the following for loading the model: https://pytorch.org/docs/stable/generated/torch.load.html#torch.load"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Saving the hyperparameters and the fine-tuned model\n",
    "# The model size is around 500 MB\n",
    "training_constants = [mask_prob, window_size, batch_size, total_epoch_number, learning_rate, weight_decay_coefficient, shuffle, rng_seed, size_limit_proportion_train, size_limit_proportion_valid]\n",
    "result_dict = {\"training_constants\": training_constants, \"validation_similarity\": average_similarity}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Generating non-existing filenames\n",
    "file_index = 0\n",
    "while os.path.exists(f\"./saved_models/model_{file_index}\"):\n",
    "    file_index += 1\n",
    "\n",
    "model_filepath = f\"./saved_models/model_{file_index}\"\n",
    "hparameter_filepath = f\"./saved_models/hparameter_{file_index}\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "torch.save(model_b1, model_filepath)\n",
    "# Saving the hyperparameters\n",
    "with open(hparameter_filepath, \"wb\") as fw:\n",
    "    pickle.dump(result_dict, fw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
